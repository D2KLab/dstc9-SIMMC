Hi Matteo, thank you for your clarifying questions. 

`state_graph_{idx}` refers to the graph representation of the cumulative dialog and the multimodal contexts known to the user, 
each at a different phase during the dialog (e.g. via a multimodal action of showing items, an assistant providing information, a user providing preferences, etc.). 

- state_graph_0: initial state before the start of the user utterance
- state_graph_1: state modified after the user utterance 
- state_graph_2: final state modified after the assistant utterance & assistant action.

Participants may use this information for inspection, or as additional training signals for some of the sub-tasks (but not at inference time). 
`belief_state`, `system_belief_state`, and `visual_objects` provide the same information. 

Each state graph is represented as follows:
```
{
    <str> obj_name: {
        <str> attribute_name: <list> or <str> attribute_values
    }
}
```

`act` in `belief_state` is the main target dialog act in the dialog context, which has a coarser representation of NLU `intent` fields in `transcript_annotated`, 
which includes the smart prefixes, slot attributes, etc. that are detailed in Section 4.2 of our paper. 
The goal of the Sub-task #3 is to correctly predict `act` labels in `belief_state`. You may use other annotations as additional training signals.

Please refer to Table 4 in our paper for the full list of API actions and argument names. We will also upload the ontology of slot types in `belief_state`. 

`raw_assistant_keystrokes`: These are the raw UI interactions made by the human Assistant (wizard) using the Unity interface during data collection. 
[[ These are very noisy as the human assistantsâ€™ tended to explore the catalogue before settling on and sharing their view. 
The Unity UI also operated asynchronously to the messaging interface. ]] 
We distil target actions for the action prediction task (sub-task #1) from these raw keystrokes and NLU/NLG annotation

The details above are updated in the README doc as well.

Please let us know if you have feedback or thoughts on any other resources that would make the challenge more accessible. 
We will keep you posted when there are new releases/code that is made available. 

Best,
Shane